---
title: "Make burden data" 
author: "Kendra Wyant"
date: "`r lubridate::today()`"
format: 
  html: 
    embed-resources: true
    toc: true 
    toc_depth: 4
editor_options: 
  chunk_output_type: console
---   

## Notes

This script pulls out burden questions from processed monthly surveys. It does EDA on burden data and saves out final processed burden data into 2 files (`burden_quant.csv` and `burden_qual.csv`). 


Decisions:    

- subid 1197 given survey 11 times. Study start date per intake was 11-02-2022. Will keep first burden survey on 3-02-2023 as this lines up with fourth month on study.   

- subid 1257 given survey 5 times. Study start date per intake was 1-26-2023. Keep first survey on 6-7-2023 (4 months and 1 week after study start).   

- Subid 1006 and 1009 took the survey twice (once 2 months in and once at the end of study). Keep first survey, but note that the first survey is earlier than other subids.   

- Subid 1410 took burden survey twice on same day (within 30 min). Keep first survey.   

- 10 subids completed duplicate surveys one month apart. 

    - Susan's explanation as to why there are back to back surveys (1 month apart): As for people who have them back to back, that I can explain more easily. Here's the code for selecting which survey they get: It's delivered on month 4 or month 12. HOWEVER, it was originally delivered on month 3 or 12.  We realized month 3 was technically only their second dynamic monthly survey, so we changed it to month 4 - meaning a few people who got it at month 3 took it the next month as well.
    - Keep first survey as these generally look more complete. 


- Only one subid excluded for not being in US - subid 1245

    - During eda on EMA utc_offset it was determined they had modal UTC offset of 60 (+5 hours). This puts them in either Islamabad, Ekaterinburg, Karachi, or Tashkent. This subid had 61 lapses reported. At other times there UTC offset is 600 (+10 hours).   


## Set up
```{r}
#| include: false

options(conflicts.policy = "depends.ok")
library(tidyverse) 
library(janitor)

devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true")

theme_set(theme_classic())

path_shared <- format_path("risk2/data_processed/shared")
path_burden <- format_path("risk2/data_processed/burden2")
```

## Read in monthly surveys

```{r}
month_survey <- read_csv(here::here(path_shared, "survey_monthly.csv"),
                         col_types = "dccTTccccccccccccccccccccccccccccccccc") |> 
   # filter out subid 1245
  filter(subid != 1245)
```


## Pull out burden data

```{r}
burden <- month_survey |> 
  select(subid, user_survey_guid, start_date, contains("_interfer"),  
         contains("_dislike"), contains("_comments")) |> 
  rename(daily_update_interfere = daily_update_interfer,
         video_checkin_interfere = video_checkin_interfer) |> 
  filter(!(is.na(daily_update_interfere) & is.na(video_checkin_interfere) &
             is.na(monthly_update_interfere))) |> 
  glimpse()
```




## EDA

### Read in intake to get study start dates


```{r}
study_start <- read_csv(here::here(path_shared, "survey_intake.csv"),
                         show_col_types = FALSE) |> 
  select(subid, study_start = start_date) |> 
  mutate(study_start = as_datetime(study_start, tz = "America/Chicago")) |> 
  unique() |> 
  glimpse()
```

add study start date to burden for eda
```{r}
burden <- burden |> 
  left_join(study_start, by = "subid") |> 
  relocate(study_start, .after = subid) |> 
  glimpse()
```


### Check surveys per subid 

**Participants were asked burden questions in the third month and last month - they should have a total of 2 sets of responses if they completed the entire study.**   

Most participants only have one survey - Susan said there was a glitch in that the burden questions were not added to their last survey.


`r nrow(burden)` observations.    
`r length(unique(burden$subid))` unique subids. 


Subids with more than 1 survey
```{r}
burden |> 
  group_by(subid) |> 
  count() |> 
  arrange(desc(n)) |> 
  filter(n > 1)
```


subid 1197 given survey 11 times. Study start date per intake was 11-02-2022. Will keep first burden survey on 3-02-2023 as this lines up with fourth month on study.
```{r}
burden |> 
  filter(subid == 1197) |> 
  arrange(start_date) |> 
  view()
```

```{r}
guids_1197 <- burden |> 
  filter(subid == 1197) |> 
  arrange(start_date) |> 
  slice(-1) |> 
  pull(user_survey_guid)

burden <- burden |> 
  filter(!user_survey_guid %in% guids_1197)
```

subid 1257 given survey 5 times. Study start date per intake was 1-25-2023. Keep first survey on 6-7-2023 (about 4 months and 1 week after study start).     

```{r}
burden |> 
  filter(subid == 1257) |> 
  arrange(start_date) |> 
  view()
```

```{r}
guids_1257 <- burden |> 
  filter(subid == 1257) |> 
  arrange(start_date) |> 
  slice(-1) |> 
  pull(user_survey_guid)

burden <- burden |> 
  filter(!user_survey_guid %in% guids_1257)
```

Check dates between remaining participants with two surveys.  

```{r}
subids_2_surveys <- burden |> 
  group_by(subid) |> 
  count() |> 
  filter(n > 1) |> 
  pull(subid)
```

```{r}
burden |> 
  filter(subid %in% subids_2_surveys) |> 
  arrange(subid, start_date) |> 
  view()
```

subid 1410 took survey four months in and twice at end of study - keep first survey
```{r}
burden <- burden |> 
  filter(!user_survey_guid %in% c("75fc6f11-0400-470f-8481-4e1536bf45c9", 
                                  "f8d08937-43da-480f-8394-405e28777f9e"))
```


Subid 1006 and 1009 took the survey twice (once 2 months in and once at the end of study). Keep first survey, but note that the first survey is earlier than other subids
```{r}
burden <- burden |> 
  filter(!user_survey_guid %in% c("90a2569f-04e6-488a-bd7b-2699dd555cd0", 
  "c23ea417-e2c3-476e-af79-2ea7ac0cb7ba"))
```


Subid 1410 took burden survey twice on same day (within 30 min). Keep first survey.
```{r}
burden <- burden |> 
  filter(user_survey_guid != "47ebbaf5-1715-4092-8836-d290981889b1")
```

Other surveys were one month apart.   

Susan's explanation as to why there are back to back surveys (1 month apart):   
As for people who have them back to back, that I can explain more easily. Here's the code for selecting which survey they get: It's delivered on month 4 or month 12. HOWEVER, it was originally delivered on month 3 or 12.  We realized month 3 was technically only their second dynamic monthly survey, so we changed it to month 4 - meaning a few people who got it at month 3 took it the next month as well.

```{r}
burden |> 
  filter(subid %in% subids_2_surveys & !subid %in% c(1410, 1006, 1009)) |> 
  group_by(subid) |> 
  summarise(min = min(start_date),
            max = max(start_date)) |> 
  mutate(range_days = as.numeric(difftime(max, min, units = "days")))
```

Keep first survey as these generally look more complete. 
```{r}
guids_2_surveys <- burden |> 
  filter(subid %in% subids_2_surveys & !subid %in% c(1410, 1006, 1009)) |> 
  arrange(subid, start_date) |>
  group_by(subid) |> 
  slice(-1) |> 
  pull(user_survey_guid)

burden <- burden |> 
  filter(!user_survey_guid %in% guids_2_surveys)
```

Remove subid 1441 as they only completed survey at end of study
```{r}
burden <- burden |> 
  filter(!subid == 1441)
```


`r nrow(burden)` observations.    
`r length(unique(burden$subid))` unique subids. 


### Time between study start and burden survey

*Missing intake study start date for subid 1069 because they took monthly as intake - confirmed they took burden four months into study.*    

Burden surveys were given after 62 - 142 days on study
```{r}
burden |> 
  mutate(burden_month = round(start_date - study_start)) |> 
  tabyl(burden_month)
```


## Burden quant

```{r}
burden_quant <- burden |> 
  select(-ends_with("comments"))
```

### Missing values
```{r}
naniar::miss_var_summary(burden_quant)
```

Look at surveys with missing data - looks fine, surveys are mostly complete

```{r}
burden_quant |> 
  filter(is.na(sms_content_dislike) | is.na(monthly_update_dislike) | 
           is.na(sms_phone_logs_dislike)) |> 
  view()
```


## Burden qual

```{r}
burden_qual <- burden |> 
 select(subid:start_date, ends_with("_comments")) 
```

### Missing values
```{r}
naniar::miss_var_summary(burden_qual)
```

25 surveys have no qual data
```{r}
burden_qual |> 
  filter(is.na(sms_content_comments) & is.na(monthly_update_comments) & 
           is.na(sms_phone_logs_comments) & is.na(gps_comments) &
           is.na(daily_updates_comments)) 
```

## Save out data sets

```{r}
burden_quant |> 
  write_csv(file.path(path_burden, "burden_quant.csv"))
```

```{r}
burden_qual |> 
  write_csv(file.path(path_burden, "burden_qual.csv"))
```

