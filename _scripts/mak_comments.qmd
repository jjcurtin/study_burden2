---
title: "Make final comments" 
author: "Kendra Wyant"
date: "`r lubridate::today()`"
format: 
  html: 
    embed-resources: true
    toc: true 
    toc_depth: 4
editor_options: 
  chunk_output_type: console
---   

## Notes

This script creates a dataframe of comments to be coded.

1. It pivots data frame long so that each row represents one comment. 

2. It filters out comments that equate to NA (e.g., None, No, Na, No comments)


**These final comments will be compared across coders 1 and 2 and to be used as inputs into all text analyses.**


## Set up
```{r}
#| include: false

options(conflicts.policy = "depends.ok")
library(tidyverse) 
library(janitor)

devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true")

theme_set(theme_classic())

path_burden <- format_path("studydata/risk2/data_processed/burden2")
```

## Read in data

```{r}
burden_qual <- read_csv(here::here(path_burden, "burden_qual.csv"),
                         show_col_types = FALSE) |> 
  glimpse()
```


### Format data


```{r}
burden_long <- burden_qual |> 
  select(-c(study_start:complete_date)) |> 
  pivot_longer(daily_updates_comments:sms_content_comments, 
               names_to = "data",
               values_to = "comment") |> 
  glimpse()
```

```{r}
burden_long <- burden_long |> 
  mutate(data = str_remove(data, "_comments"),
         data = case_when(data == "daily_updates" ~ "daily_update",
                          data == "video_checkin" ~ "video",
                          TRUE ~ data)) |> 
  glimpse()
```



### Filter out stop words that equate to NA or no comment

Look at comments less than 3 words to generate stop word dictionary
```{r}
stop_words <- burden_long |> 
  mutate(word_count = str_count(comment, '\\w+')) |> 
  filter(word_count < 3)

stop_words <- stop_words |> 
  filter(!comment %in% c("Accountability", "To personal", "Enjoy them", 
                         "Not preferred", "Its alright", "Its long", 
                         "My privqcy", "Like it",  "Privatee", "I understand", 
                         "Great survey", "Easy questions", "Easy calls", 
                         "Kinda weird", "To long", "Necessary", "Its cool", 
                         "Easy", "It helps", "Helps", "help", "Great  update",
                         "Positive", "Good", "Helpful", "Good experience", "Feel safe", 
                         "Verry happy", "Happy", "Reality check", "Its easy", "Nothingbyo hide"))
```

Comments to remove
```{r}
stop_words |> 
  pull(comment)

burden_long <- burden_long |> 
  filter(!is.na(comment) & !comment %in% stop_words$comment)
```

Other comments to remove - based on EDA and previous coding iterations
```{r}
burden_long <- burden_long |> 
  filter(!comment %in% c("Nothing at this time", "Same as previous answer", 
                         "Same as previously", "No comments really", 
                         "Same answers as fir the daily update, and daily videos",
                         "Nothing to share", "Same as location", 
                         "Same feelings for this as i am with my data", 
                         "I have nothing to say about it", 
                         "Feel the same way about my text messages as I feel about the phone call.",
                         "I haven't had to say about the survey", 
                         "Pp I love that story about it", "Pp nothing meant to say that",
                         "Maybe this month ill do a video..", 
                          "Oh well. Eh?", "Don't r", "I haven't had to say about the survey\n\n", 
                         "No issues as of lately\n"))
```



### Final counts

Total comments: `r nrow(burden_long)`

Unique subids: `r length(unique(burden_long$subid))`



### Save out data
```{r}
burden_long |> 
  write_csv(here::here(path_burden, "final_comments.csv"))
```

