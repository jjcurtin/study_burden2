---
title: "Make burden data" 
author: "Kendra Wyant"
date: "`r lubridate::today()`"
format: 
  html: 
    embed-resources: true
    toc: true 
    toc_depth: 4
editor_options: 
  chunk_output_type: console
---   

## Notes

This script pulls out burden questions from processed monthly surveys. It does EDA on burden data and saves out final processed burden data into 2 files (`burden_quant.csv` and `burden_qual.csv`). 

Outstanding:   

- Missing intake study start date for subid 1069 at the moment - need to investigate, but does not invalidate burden data.

Decisions:    

- subid 1197 given survey 11 times. Study start date per intake was 11-02-2022. Will keep first burden survey on 3-02-2023 as this lines up with fourth month on study.   

- subid 1257 given survey 5 times. Study start date per intake was 1-26-2023. Keep first survey on 6-7-2023 (4 months and 1 week after study start).   

- Subid 1006 and 1009 took the survey twice (once 2 months in and once at the end of study). Keep first survey, but note that the first survey is earlier than other subids.   

- Subid 1410 took burden survey twice on same day (within 30 min). Keep first survey.   

- 10 subids completed duplicate surveys one month apart. 

    - Susan's explanation as to why there are back to back surveys (1 month apart): As for people who have them back to back, that I can explain more easily. Here's the code for selecting which survey they get: It's delivered on month 4 or month 12. HOWEVER, it was originally delivered on month 3 or 12.  We realized month 3 was technically only their second dynamic monthly survey, so we changed it to month 4 - meaning a few people who got it at month 3 took it the next month as well.
    - Keep first survey as these generally look more complete. 





## Set up
```{r}
#| include: false

options(conflicts.policy = "depends.ok")
library(tidyverse) 
library(janitor)

devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true")

theme_set(theme_classic())

path_processed <- format_path("studydata/risk2/data_processed/shared")
path_burden <- format_path("studydata/risk2/data_processed/burden2")
```

## Read in monthly surveys

```{r}
month_survey <- read_csv(here::here(path_processed, "survey_monthly.csv"),
                         show_col_types = FALSE) |> 
  select(subid, user_survey_guid, start_date, complete_date, variable_name, answer) |> 
  mutate(start_date = as_datetime(start_date, tz = "America/Chicago"),
         complete_date = as_datetime(complete_date, tz = "America/Chicago")) |> 
  glimpse()
```


## Pull out burden data

```{r}
burden <- month_survey |> 
  filter(str_detect(variable_name, "_interfer") | str_detect(variable_name, "_dislike") | 
           str_detect(variable_name, "_comments")) |> 
  mutate(variable_name = if_else(variable_name == "daily_update_interfer", "daily_update_interfere",
                                 variable_name),
         variable_name = if_else (variable_name == "video_checkin_interfer", "video_checkin_interfere",
                                  variable_name)) |> 
  glimpse()
```



check variable names
```{r}
tabyl(burden$variable_name)
```

Pivot wider to tidy and remove video_checkin variables since did not use this sensing method
```{r}
burden <- burden |> 
  filter(!str_detect(variable_name, "video_checkin")) |> 
  pivot_wider(names_from = variable_name, values_from = answer) |> 
  glimpse()
```


## EDA

### Read in intake to get study start dates


```{r}
study_start <- read_csv(here::here(path_processed, "survey_intake.csv"),
                         show_col_types = FALSE) |> 
  select(subid, study_start = start_date) |> 
  mutate(study_start = as_datetime(study_start, tz = "America/Chicago")) |> 
  unique() |> 
  glimpse()
```

add study start date to burden for eda
```{r}
burden <- burden |> 
  left_join(study_start, by = "subid") |> 
  relocate(study_start, .after = subid) |> 
  glimpse()
```


### Check surveys per subid 

**Participants were asked burden questions in the third month and last month - they should have a total of 2 sets of responses if they completed the entire study.**   

Most participants only have one survey - Susan said there was a glitch in that the burden questions were not added to their last survey.


`r nrow(burden)` observations.    
`r length(unique(burden$subid))` unique subids. 


Subids with more than 1 survey
```{r}
burden |> 
  group_by(subid) |> 
  count() |> 
  arrange(desc(n)) |> 
  filter(n > 1)
```


subid 1197 given survey 11 times. Study start date per intake was 11-02-2022. Will keep first burden survey on 3-02-2023 as this lines up with fourth month on study.
```{r}
burden |> 
  filter(subid == 1197) |> 
  arrange(start_date) |> 
  view()
```

```{r}
guids_1197 <- burden |> 
  filter(subid == 1197) |> 
  arrange(start_date) |> 
  slice(-1) |> 
  pull(user_survey_guid)

burden <- burden |> 
  filter(!user_survey_guid %in% guids_1197)
```

subid 1257 given survey 5 times. Study start date per intake was 1-25-2023. Keep first survey on 6-7-2023 (about 4 months and 1 week after study start).     

```{r}
burden |> 
  filter(subid == 1257) |> 
  arrange(start_date) |> 
  view()
```

```{r}
guids_1257 <- burden |> 
  filter(subid == 1257) |> 
  arrange(start_date) |> 
  slice(-1) |> 
  pull(user_survey_guid)

burden <- burden |> 
  filter(!user_survey_guid %in% guids_1257)
```

Check dates between remaining participants with two surveys.  

```{r}
subids_2_surveys <- burden |> 
  group_by(subid) |> 
  count() |> 
  filter(n > 1) |> 
  pull(subid)
```

```{r}
burden |> 
  filter(subid %in% subids_2_surveys) |> 
  arrange(subid, start_date) |> 
  view()
```

Subid 1006 and 1009 took the survey twice (once 2 months in and once at the end of study). Keep first survey, but note that the first survey is earlier than other subids
```{r}
burden <- burden |> 
  filter(!user_survey_guid %in% c("90a2569f-04e6-488a-bd7b-2699dd555cd0", 
  "c23ea417-e2c3-476e-af79-2ea7ac0cb7ba"))
```


Subid 1410 took burden survey twice on same day (within 30 min). Keep first survey.
```{r}
burden <- burden |> 
  filter(user_survey_guid != "47ebbaf5-1715-4092-8836-d290981889b1")
```

Other surveys were one month apart.   

Susan's explanation as to why there are back to back surveys (1 month apart):   
As for people who have them back to back, that I can explain more easily. Here's the code for selecting which survey they get: It's delivered on month 4 or month 12. HOWEVER, it was originally delivered on month 3 or 12.  We realized month 3 was technically only their second dynamic monthly survey, so we changed it to month 4 - meaning a few people who got it at month 3 took it the next month as well.

```{r}
burden |> 
  filter(subid %in% subids_2_surveys & !subid %in% c(1410, 1006, 1009)) |> 
  group_by(subid) |> 
  summarise(min = min(complete_date),
            max = max(complete_date)) |> 
  mutate(range_days = as.numeric(difftime(max, min, units = "days")))
```

Keep first survey as these generally look more complete. 
```{r}
guids_2_surveys <- burden |> 
  filter(subid %in% subids_2_surveys & !subid %in% c(1410, 1006, 1009)) |> 
  arrange(subid, start_date) |>
  group_by(subid) |> 
  slice(-1) |> 
  pull(user_survey_guid)

burden <- burden |> 
  filter(!user_survey_guid %in% guids_2_surveys)
```


`r nrow(burden)` observations.    
`r length(unique(burden$subid))` unique subids. 


### Time between study start and burden survey

*Missing intake study start date for subid 1069 at the moment - need to investigate.*    

Burden surveys were given after 62 - 142 days on study
```{r}
burden |> 
  mutate(burden_month = round(start_date - study_start)) |> 
  tabyl(burden_month)
```


## Burden quant

```{r}
burden_quant <- burden |> 
  select(-ends_with("comments"))
```

### Missing values
```{r}
naniar::miss_var_summary(burden_quant)
```

Look at surveys with missing data - looks fine, surveys are mostly complete

```{r}
burden_quant |> 
  filter(is.na(sms_content_dislike) | is.na(monthly_update_dislike) | 
           is.na(sms_phone_logs_dislike)) |> 
  view()
```


## Burden qual

```{r}
burden_qual <- burden |> 
 select(subid:complete_date, ends_with("_comments")) 
```

### Missing values
```{r}
naniar::miss_var_summary(burden_qual)
```

25 surveys have no qual data
```{r}
burden_qual |> 
  filter(is.na(sms_content_comments) & is.na(monthly_update_comments) & 
           is.na(sms_phone_logs_comments) & is.na(gps_comments) &
           is.na(daily_updates_comments)) 
```

## Save out data sets

```{r}
burden_quant |> 
  write_csv(file.path(path_burden, "burden_quant.csv"))
```

```{r}
burden_qual |> 
  write_csv(file.path(path_burden, "burden_qual.csv"))
```

