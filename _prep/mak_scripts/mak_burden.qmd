---
title: "Make burden data" 
author: "Kendra Wyant"
date: "`r lubridate::today()`"
format: 
  html: 
    embed-resources: true
    toc: true 
    toc_depth: 4
editor_options: 
  chunk_output_type: console
---   

## Notes

This script pulls out burden questions from processed monthly surveys. It does EDA on burden data and saves out final processed burden data into 2 files (`burden_quant.csv` and `burden_qual.csv`). 

Decisions:

- Subid 1197 is excluded. They completed 11 burden surveys but had missing values in all fields for all surveys.

- Subid 1257 is excluded. They completed 5 burden surveys but had missing values in all fields for all surveys.

- Only 12 out of 245 participants completed a second burden survey. Only 2 people with a second survey completed the survey more than a month after their first survey and one of these people had NAs on comments for second survey. Decision to only keep first survey. 

- 19 subids have no qual data (all NAs) and will be excluded

- 133 partcicipants have no quant data! Need to look at monthly cleaning script to see if problem introduced or these data are actually missing. We are only using qualitative data at the current moment. Since quant data only really adds a likert scale measure of dislike. 





## Set up
```{r}
#| include: false

options(conflicts.policy = "depends.ok")
library(tidyverse) 
library(janitor)

devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true")

theme_set(theme_classic())

path_processed <- format_path("studydata/risk2/data_processed/shared")
path_prep <- format_path("studydata/risk2/data_processed/prep")
```

## Read in monthly surveys

```{r}
month_survey <- read_csv(here::here(path_processed, "survey_monthly.csv"),
                         show_col_types = FALSE) |> 
  glimpse()
```


## Pull out burden data

```{r}
burden <- month_survey |> 
  filter(str_detect(variable_name, "_interfer") | str_detect(variable_name, "_dislike") | 
           str_detect(variable_name, "_comments")) |> 
  mutate(variable_name = if_else(variable_name == "daily_update_interfer", "daily_update_interfere",
                                 variable_name),
         variable_name = if_else (variable_name == "video_checkin_interfer", "video_checkin_interfere",
                                  variable_name)) |> 
  glimpse()
```

Remove unused variables

```{r}
burden |> 
  tabyl(loop_node)

burden |> 
  tabyl(status)

burden <- burden |> 
  select(-c(loop_node, status))
```


check variable names

```{r}
tabyl(burden$variable_name)
```


## EDA

### Check surveys per subid 

**Participants were asked burden questions in the third month and last month - they should have a total of 2 sets of responses if they completed the entire study.**   

Most participants only have one survey

```{r}
n_surveys <- burden |> 
  group_by(subid, user_survey_guid) |> 
  slice(1) |> 
  group_by(subid) |> 
  count() |> 
  arrange(desc(n))

n_surveys |> 
  tabyl(n)
```



Two subids have more than two surveys

```{r}
n_surveys |> 
  filter(n > 2)
```


subid 1197 
```{r}
burden |> 
  filter(subid == 1197) |> 
  view()
```

All missing values in subid 1197's surveys. **They will be excluded from study.**
```{r}
burden |> 
  filter(subid == 1197) |> 
  tabyl(answer)
```


subid 1257

```{r}
burden |> 
  filter(subid == 1257) |> 
  view()
```

All missing values in subid 1257's surveys. **They will be excluded from study.**
```{r}
burden |> 
  filter(subid == 1257) |> 
  tabyl(answer)
```

```{r}
burden <- burden |> 
  filter(!subid %in% c(1197, 1257))
```

### Check dates between two surveys

```{r}
(burden_2_surveys <- burden |> 
  filter(subid %in% subset(n_surveys, n > 1)$subid) |> 
  group_by(subid, user_survey_guid) |> 
  slice(1) |> 
  ungroup() |> 
  select(subid, complete_date) |> 
  mutate(complete_date = as_datetime(complete_date, tz = "America/Chicago"))) 
```

Most surveys were at least a month apart
```{r}
burden_2_surveys |> 
  group_by(subid) |> 
  summarise(min = min(complete_date),
            max = max(complete_date)) |> 
  mutate(range_days = as.numeric(difftime(max, min, units = "days")))
```

Subid 1410's surveys were 20 minutes apart
```{r}
burden |> 
  filter(subid == 1410) |> 
  arrange(user_survey_guid) |> 
  view()
```

First survey has more complete answers. Will discard second survey. 

```{r}
burden <- burden |> 
  filter(!user_survey_guid == "47ebbaf5-1715-4092-8836-d290981889b1")

burden_2_surveys <- burden_2_surveys |> 
  filter(!subid == 1410)
```

This leaves 12 subids with two burden surveys. Only 2 completed second survey more than a month after first survey. 
```{r}
burden_2_surveys |> 
  group_by(subid) |> 
  summarise(min = min(complete_date),
            max = max(complete_date)) |> 
  mutate(range_days = as.numeric(difftime(max, min, units = "days")))
```

1009, 1116, 1133, and  have all NA's for comments on second survey.   
1104 only has one comment about video checkin across surveys.  
1047 only has one comment on second survey consistent with first survey.  
1044 only has a few logistical comments/recommendations in second survey. 
1014 only has two comments in second survey consistent with first survey.  
1182 comments on second survey consistent with first survey.

Lose a few comments with 1006, 1010, 1017, 1422
```{r}
burden |> 
  filter(subid %in% burden_2_surveys$subid) |> 
  filter(str_detect(variable_name, "comments")) |> 
  arrange(subid, complete_date) |> 
  select(subid, complete_date, variable_name, answer) |> 
  view()
```

Will remove second survey. 
```{r}
exclude <- burden |> 
  filter(subid %in% burden_2_surveys$subid) |> 
  group_by(subid) |>  
  arrange(desc(complete_date)) |> 
  slice(1)

burden <- burden |> 
  filter(!user_survey_guid %in% exclude$user_survey_guid)
```

## Burden quant

```{r}
burden_quant <- burden |> 
  filter(!str_detect(variable_name, "_comments")) 
```

### Missing values
```{r}
burden_quant |> 
  group_by(variable_name) |> 
  summarize(n_missing = sum(is.na(answer)))
```

check for surveys with all missing quant values

```{r}
(missing_data <- burden_quant |> 
  group_by(subid) |> 
  summarize(n_missing = sum(is.na(answer))) |> 
  filter(n_missing == 9))
```

**We have 143 participants who have missing burden quant data!!**

```{r}
burden_quant |> 
  filter(subid %in% missing_data$subid) |> 
  view()
```


## Burden qual

```{r}
burden_qual <- burden |> 
  filter(str_detect(variable_name, "_comments")) 
```

### Missing values
```{r}
burden_qual |> 
  group_by(variable_name) |> 
  summarize(n_missing = sum(is.na(answer)))
```

check for surveys with all missing qual values

```{r}
(missing_data <- burden_qual |> 
  group_by(subid) |> 
  summarize(n_missing = sum(is.na(answer))) |> 
  filter(n_missing == 6))
```

**19 subids have no qual data and will be excluded**

```{r}
burden_qual |> 
  filter(subid %in% missing_data$subid) |> 
  view()
```

```{r}
burden_qual <- burden_qual |> 
  filter(!subid %in% missing_data$subid)
```


## Save out data sets

```{r}
burden_quant |> 
  write_csv(file.path(path_prep, "burden_quant.csv"))
```

```{r}
burden_qual |> 
  mutate(data = str_remove(variable_name, "_comments"),
         data = case_when(data == "daily_updates" ~ "daily_update",
                          data == "video_checkin" ~ "video",
                          TRUE ~ data)) |> 
  select(subid, user_survey_guid, complete_date,
         data, answer) |> 
  write_csv(file.path(path_prep, "burden_qual.csv"))
```

